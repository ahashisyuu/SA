{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def load_rawData(data_path):\n",
    "    trainingset = None\n",
    "    validationset = None\n",
    "    testa = None\n",
    "    listdir = os.listdir(data_path)\n",
    "    for name in listdir:\n",
    "        if 'trainingset.csv' in name:\n",
    "            trainingset = pd.read_csv(os.path.join(data_path, name))\n",
    "        if 'validationset.csv' in name:\n",
    "            validationset = pd.read_csv(os.path.join(data_path, name))\n",
    "        if 'testa.csv' in name:\n",
    "            testa = pd.read_csv(os.path.join(data_path, name))\n",
    "    return trainingset, validationset, testa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset, validationset, testa = load_rawData('../rawData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对有标签的数据进行处理\n",
    "trainingset.iloc[:, 2:] = trainingset.iloc[:, 2:].apply(lambda x: x+2)\n",
    "validationset.iloc[:, 2:] = validationset.iloc[:, 2:].apply(lambda x: x+2)\n",
    "# 标签onehot化\n",
    "def one_hot(number):\n",
    "    li = [0, 0, 0, 0]\n",
    "    li[number] = 1\n",
    "    return li\n",
    "\n",
    "def one_hot_series(series):\n",
    "    return series.apply(one_hot)\n",
    "\n",
    "\n",
    "trainingset.iloc[:, 2:] = trainingset.iloc[:, 2:].apply(one_hot_series)\n",
    "validationset.iloc[:, 2:] = validationset.iloc[:, 2:].apply(one_hot_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "def tokenize(content, filters='！!“”\"#$%&（）()*+,，-。、./:：；;‘’《》……·<=>?@[\\\\]^_`{|}~\\t\\n'):\n",
    "    return [token for token in jieba.cut(content[1:-1]) if token not in filters]\n",
    "\n",
    "trainingset['content'] = trainingset['content'].apply(tokenize)\n",
    "validationset['content'] = validationset['content'].apply(tokenize)\n",
    "testa['content'] = testa['content'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_path = '../data'\n",
    "\n",
    "trainingset.to_csv(os.path.join(new_data_path, 'trainingset.csv'))\n",
    "validationset.to_csv(os.path.join(new_data_path, 'validationset.csv'))\n",
    "testa.to_csv(os.path.join(new_data_path, 'testa.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainingset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(trainingset.iloc[:, 2][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "keys_list = trainingset.keys().tolist()[2:]\n",
    "print(keys_list)\n",
    "arrangement_map = {key: i for i, key in enumerate(keys_list)}\n",
    "map_name = os.path.join('../data', 'arrangement_map.pkl')\n",
    "keys_list_name = os.path.join('../data', 'keys_list.txt')\n",
    "with open(map_name, 'wb') as fw, open(keys_list_name, 'w') as fw2:\n",
    "    pkl.dump(arrangement_map, fw)\n",
    "\n",
    "    for key in keys_list:\n",
    "        fw2.write(key + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(doc_list, dic_count):\n",
    "    # 计算词频\n",
    "    # 如果字典里有该单词则加1，否则添加入字典\n",
    "#     print(dic_count.get('k'))\n",
    "    for key in doc_list:\n",
    "        if key in dic_count.keys():\n",
    "            dic_count[key] = dic_count[key] + 1\n",
    "        else:\n",
    "            dic_count[key] = 1\n",
    "\n",
    "\n",
    "count_dic = {}\n",
    "# trainingset['content'].apply(word_count, args=(count_dic,))\n",
    "validationset['content'].apply(word_count, args=(count_dic,))\n",
    "c = 0\n",
    "for key,value in count_dic:\n",
    "    print(key, value)\n",
    "    c += 1\n",
    "    if c == 10:\n",
    "        break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吼 吼\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2cc71d559026>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcount_dic\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for key,value in count_dic:\n",
    "    print(key, value)\n",
    "    c += 1\n",
    "    if c == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
